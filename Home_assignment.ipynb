{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Home assignment",
      "provenance": [],
      "authorship_tag": "ABX9TyPrYX66SyjLxDCWCfIxdkaT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattherbert1/DreamTeam-deep-learning/blob/main/Home_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4AIC6SJVhil"
      },
      "source": [
        "# Home assignment\n",
        "(link to the repo: https://github.com/mattherbert1/DreamTeam-deep-learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwL2v1KdYG2"
      },
      "source": [
        "In our home assignment the goal is to train a neural network to live detect traffic signs and traffic lights through a Python client in CARLA simulator (https://carla.org/), which is an open-source simulator for autonomous driving research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFw8KO5CVweQ"
      },
      "source": [
        "## Gathering, cleaning and sorting dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH2w28bAWBxg"
      },
      "source": [
        "The sources of our dataset is listed below:\n",
        "\n",
        "\n",
        "*   The German Traffic Sign Recognition Benchmark (for traffic signs): http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset\n",
        "*   LaRA Traffic Light dataset (for traffic lights): http://www.lara.prd.fr/benchmarks/trafficlightsrecognition\n",
        "*   A limited dataset from CARLA: https://github.com/DanielHfnr/Carla-Object-Detection-Dataset\n",
        "\n",
        "Unfortunately, we did not have the resources to obtain large dataset only from Carla, thus we use datasets from real life, too.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW_7ziIKLEAE"
      },
      "source": [
        "LaRA dataset contains frames of a video record of a route and labels to these frames with bounding boxes marking the traffic light. The following script is for reshaping the LaRA dataset (lara3d_reformat.py) to images with uniformed resolution about the actual traffic lights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0mG4fxtUNU6"
      },
      "source": [
        "import csv\n",
        "import cv2 as cv\n",
        "from math import floor, ceil\n",
        "\n",
        "# reshape bounding box to square\n",
        "def crop2square(original_min, original_max, difference):\n",
        "    new_min = original_min - floor(difference / 2)\n",
        "    new_max = original_max + ceil(difference / 2)\n",
        "    return new_min, new_max\n",
        "\n",
        "# move all of the part of the bounding box inside of the image\n",
        "def shift(y_down, y_up, x_left, x_right, shape):\n",
        "    if y_down < 0:\n",
        "        y_up += abs(y_down)\n",
        "        y_down = 0\n",
        "    if y_up > shape[0]:\n",
        "        y_down -= y_up - shape[0]\n",
        "        y_up = shape[0]\n",
        "    if x_left < 0:\n",
        "        x_right += abs(x_left)\n",
        "        x_left = 0\n",
        "    if x_right > shape[1]:\n",
        "        x_left -= x_right - shape[1]\n",
        "        x_right = shape[1]\n",
        "    return y_down, y_up, x_left, x_right\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # reading original labels from file\n",
        "    with open('./Lara3D/labels.txt') as label_file:\n",
        "        labels = []\n",
        "        for row in label_file:\n",
        "            row_split = row.rstrip().split(' ')\n",
        "\n",
        "            # dropping ambigiuous labels\n",
        "            if row_split[10] == 'ambiguous':\n",
        "                continue\n",
        "            traffic_light = [''.join(row_split[8:10])]\n",
        "            labels.append([row_split[2].zfill(6)] + row_split[3:7] + traffic_light + [row_split[10]])\n",
        "    print(len(labels))\n",
        "    counter = 0\n",
        "    csv_rows = []\n",
        "    state_counter = {\"stop\": 0, \"warning\": 0, \"go\": 0}\n",
        "\n",
        "    # reading images using labels read above\n",
        "    for label in labels:\n",
        "        image = cv.imread('./Lara3D/frame_{}.jpg'.format(label[0]))\n",
        "        \n",
        "        # top left and bottom right corners of the bounding box\n",
        "        bndymin = int(label[2])\n",
        "        bndymax = int(label[4])\n",
        "        bndxmin = int(label[1])\n",
        "        bndxmax = int(label[3])\n",
        "\n",
        "        # dimensions of the bounding box\n",
        "        width = bndxmax - bndxmin\n",
        "        height = bndymax - bndymin\n",
        "\n",
        "        # dropping traffic lamps that have too many missing parts (the original bounding box can be partly outside of the image)\n",
        "        if bndymin < 0 and abs(bndymin) / height >= 0.125:\n",
        "            continue\n",
        "        if bndymax > image.shape[0] and (bndymax - image.shape[0]) / height >= 0.125:\n",
        "            continue\n",
        "        if bndxmin < 0 and abs(bndxmin) / width >= 0.5:\n",
        "            continue\n",
        "        if bndxmax > image.shape[1] and (bndxmax - image.shape[1]) / width >= 0.5:\n",
        "            continue\n",
        "\n",
        "        # top left and bottom right corner of the bounding box that can actually be seen on the image\n",
        "        ymin = max(bndymin, 0)\n",
        "        ymax = min(bndymax, image.shape[0])\n",
        "        xmin = max(bndxmin, 0)\n",
        "        xmax = min(bndxmax, image.shape[1])\n",
        "\n",
        "        # recalculating dimensions of the bounding box\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        # dropping low res objects\n",
        "        if width < 8 or height < 8:\n",
        "            continue\n",
        "\n",
        "        difference = height - width\n",
        "        x_left, x_right, y_up, y_down = xmin, xmax, ymax, ymin\n",
        "\n",
        "        # reshaping to square the bounding box through the axis parallel to the smaller dimension of the bounding box\n",
        "        if difference < 0:\n",
        "            difference = abs(difference)\n",
        "            y_down, y_up = crop2square(ymin, ymax, difference)\n",
        "        else:\n",
        "            x_left, x_right = crop2square(xmin, xmax, difference)\n",
        "\n",
        "        # moving the square bounding box so that it cannot be partly outside of the image\n",
        "        y_down, y_up, x_left, x_right = shift(y_down, y_up, x_left, x_right, image.shape)\n",
        "\n",
        "        # print(\n",
        "        #     f\"Frame num: {label[0]}, difference: {difference}, x_left: {x_left}, x_right: {x_right}, y_down: {y_down}, y_up: {y_up}\")\n",
        "\n",
        "        # selecting pixels from read image cropped by the square bounding box\n",
        "        roi = image[y_down:y_up, x_left:x_right]\n",
        "        dimension = (69, 69)\n",
        "        # resizing the cropped object to res defined by \"dimension\"\n",
        "        resized = cv.resize(roi, dimension, interpolation=cv.INTER_AREA)\n",
        "        # generating image file\n",
        "        cv.imwrite(f\"./output/object_{str(counter).zfill(6)}.jpg\", resized)\n",
        "        # generating label row\n",
        "        csv_rows.append([str(counter).zfill(6), label[5], label[6]])\n",
        "\n",
        "        counter += 1\n",
        "        state_counter[label[-1]] += 1\n",
        "\n",
        "    # writing new labels\n",
        "    with open('./output/labels.csv', 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "        csv_writer.writerows(csv_rows)\n",
        "\n",
        "    print(counter)\n",
        "    print(state_counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vgjcYRBVFo3"
      },
      "source": [
        "Following script is for reshaping The German Traffic Sign Recognition Benchmark dataset (gtsrb_reformat.py):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH8b33QHVyl-"
      },
      "source": [
        "import cv2 as cv\n",
        "from itertools import islice\n",
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # sign class identifiers for speed limit, yield and stop signs\n",
        "    sign_ids = ['00000', '00001', '00002', '00003',\n",
        "                '00004', '00005', '00013', '00014']\n",
        "    sign_labels = ['speedlimit', 'yield', 'stop']\n",
        "    counter = 0\n",
        "\n",
        "    # reading labels.csv, which is generated by the previous script (lara3d_reformat.py)\n",
        "    # obtaining the number of the last label \n",
        "    with open(f'./output/labels.csv', \"r\") as file:\n",
        "        for line in file:\n",
        "            pass\n",
        "        last_line = line\n",
        "        counter = int(last_line.rstrip().split(',')[0])\n",
        "    label_counter = counter\n",
        "\n",
        "    # opening labels.csv for appending\n",
        "    with open(f'./output/labels.csv', \"a\") as csv_output_file:\n",
        "        csv_output_file.write(\"\\n\")\n",
        "        for sign_id in sign_ids:\n",
        "            # opening file containing labels for traffic sign class marked with \"sign_id\"\n",
        "            with open(f'./GTSRB/Final_Training/Images/{sign_id}/GT-{sign_id}.csv') as csv_input_file:\n",
        "                # reading file row by row and writing new lines to labels.csv\n",
        "                for row in islice(csv_input_file, 1, None):\n",
        "                    label_counter += 1\n",
        "                    row_split = row.rstrip().split(';')\n",
        "                    csv_output_file.write(f\"{str(label_counter).zfill(6)},TrafficSign,\")                    \n",
        "                    # writing type of sign out\n",
        "                    if int(row_split[-1]) in range(0, 6):\n",
        "                        # speedlimit \n",
        "                        csv_output_file.write(f\"{str(sign_labels[0])}\\n\")\n",
        "                    elif row_split[-1] == \"13\":\n",
        "                        # yield\n",
        "                        csv_output_file.write(f\"{str(sign_labels[1])}\\n\")\n",
        "                    elif row_split[-1] == \"14\":\n",
        "                        # stop\n",
        "                        csv_output_file.write(f\"{str(sign_labels[2])}\\n\")\n",
        "\n",
        "    # reshaping images to uniform resolution\n",
        "    for sign_id in sign_ids:\n",
        "        ppm_filenames = [f\"./GTSRB/Final_Training/Images/{sign_id}/{filename}\" for filename in\n",
        "                         os.listdir(f\"./GTSRB/Final_Training/Images/{sign_id}\") if\n",
        "                         filename.endswith('.ppm')]\n",
        "        for ppm_file in ppm_filenames:\n",
        "            counter += 1\n",
        "            image = cv.imread(ppm_file)\n",
        "            dimension = (69, 69)\n",
        "            resized = cv.resize(image, dimension, interpolation=cv.INTER_AREA)\n",
        "            cv.imwrite(f\"./output/object_{str(counter).zfill(6)}.jpg\", resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-NNYmEZdwbm"
      },
      "source": [
        "As a result of the previous scripts, a uniformed labelset (labels.csv) and imageset about traffic lights and signs have been generated.\n",
        "The following script (shuffle.py) is generating the train_labels.csv (which is shuffled), valid_labels.csv and test_labels.csv files which contain image labels marking the train, validation and test datasets and appending the small CARLA dataset to test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InKyigrnWkLk"
      },
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ratio of validation and test dataset to the whole dataset\n",
        "    valid_split = 0.2\n",
        "    test_split = 0.1\n",
        "\n",
        "    label_dict = {}\n",
        "    result_train, result_valid, result_test = [], [], []\n",
        "    # reading labels.csv row by row and add them to label_dict (key: class label of the image)\n",
        "    with open('./output/labels.csv') as file:\n",
        "        for row in file:\n",
        "            row_split = row.rstrip().split(',')\n",
        "            label_dict.setdefault((row_split[-2], row_split[-1]), []).append(row_split)\n",
        "\n",
        "    # grouping images into train, valid, test groups by labels\n",
        "    for label_specific_objects in label_dict.values():\n",
        "        nb_samples = len(label_specific_objects)\n",
        "        train = label_specific_objects[0:int(nb_samples * (1 - valid_split - test_split))]\n",
        "        valid = label_specific_objects[\n",
        "                int(nb_samples * (1 - valid_split - test_split)):int(nb_samples * (1 - test_split))]\n",
        "        test = label_specific_objects[int(nb_samples * (1 - test_split)):]\n",
        "        result_train.extend(train)\n",
        "        result_valid.extend(valid)\n",
        "        result_test.extend(test)\n",
        "\n",
        "\n",
        "    # appending Carla dataset to test dataset\n",
        "    with open('./carla-dataset/labels.csv') as file:\n",
        "        for row in file:\n",
        "            row_split = row.rstrip().split(',')\n",
        "            result_test.append(row_split)\n",
        "\n",
        "    result_train, result_valid, result_test = np.array(result_train), np.array(result_valid), np.array(result_test)\n",
        "\n",
        "    # shuffling train dataset\n",
        "    randperm = np.random.permutation(len(result_train))\n",
        "    result_train = result_train[randperm]\n",
        "\n",
        "    # writing out train, valid, test datasets to appropriate csv files    \n",
        "    with open('./output/train_labels.csv', 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "        csv_writer.writerows(result_train)\n",
        "\n",
        "    with open('./output/valid_labels.csv', 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "        csv_writer.writerows(result_valid)\n",
        "\n",
        "    with open('./output/test_labels.csv', 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "        csv_writer.writerows(result_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}